{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ebcec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ragas openai datasets python-dotenv langchain_community \n",
    "# %pip install protobuf==3.20.0\n",
    "# %pip install langchain-core\n",
    "\n",
    "# %pip install langchain-openai\n",
    "# %pip install --upgrade langchain\n",
    "# %pip install selenium\n",
    "# %pip install unstructured\n",
    "# %pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3a600e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install webdriver_manager\n",
    "#%pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd6971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from ragas import evaluate\n",
    "from datasets import Dataset \n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from ragas.metrics.critique import harmfulness\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_text_splitters.character import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import SeleniumURLLoader\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall, context_entity_recall, answer_similarity, answer_correctness\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c438e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "openai.api_key = api_key\n",
    "\n",
    "urls = [\n",
    "    \"https://en.wikipedia.org/wiki/New_York_City\",\n",
    "    \"https://en.wikipedia.org/wiki/Snow_leopard\",\n",
    "    \"https://www.britannica.com/place/Galapagos-Islands\",\n",
    "    \"https://www.birdlife.org/birds/penguins/#:~:text=The%20threats%20are%20numerous%2C%20including,is%20melting%20before%20their%20eyes.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6abeaa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import SeleniumURLLoader\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def load_content_with_selenium(url):\n",
    "    # Setup Chrome options for faster performance\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run headless for speed\n",
    "    chrome_options.add_argument(\"--disable-gpu\")  # Disable GPU for headless\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "    # Create a WebDriver with a timeout\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    driver.set_page_load_timeout(10)  # Set a page load timeout of 10 seconds\n",
    "    driver.implicitly_wait(5)  # Set an implicit wait of 5 seconds\n",
    "    #driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    driver.set_page_load_timeout(10)  # Set a timeout of 10 seconds\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        # Now pass the loaded page source to a loader or process as needed\n",
    "        page_source = driver.page_source\n",
    "        # Example: If you want to use the SeleniumURLLoader after loading:\n",
    "        loader = SeleniumURLLoader(urls=[url])\n",
    "        documents = loader.load()\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {url}: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    \"https://en.wikipedia.org/wiki/New_York_City\",\n",
    "    \"https://en.wikipedia.org/wiki/Snow_leopard\",\n",
    "   # \"https://www.britannica.com/place/Galapagos-Islands\",\n",
    "    \"https://www.birdlife.org/birds/penguins/#:~:text=The%20threats%20are%20numerous%2C%20including,is%20melting%20before%20their%20eyes.\"\n",
    "]\n",
    "\n",
    "# Load content for each URL\n",
    "documents = []\n",
    "for url in urls:\n",
    "    docs = load_content_with_selenium(url)\n",
    "    if docs:\n",
    "        documents.extend(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e3e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "690f250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentList = []\n",
    "for doc in documents:\n",
    "    d = str(doc.page_content).replace(\"\\\\n\", \" \").replace(\"\\\\t\",\" \").replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "    documentList.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8d49a11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Document\npage_content\n  str type expected (type=type_error.str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m text_chunks \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39mcreate_documents(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(documentList))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Create documents from the text chunks\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m docs \u001b[38;5;241m=\u001b[39m [Document(page_content\u001b[38;5;241m=\u001b[39mchunk) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Load a pre-trained embedding model from sentence_transformers\u001b[39;00m\n\u001b[1;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[51], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m text_chunks \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39mcreate_documents(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(documentList))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Create documents from the text chunks\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m docs \u001b[38;5;241m=\u001b[39m [\u001b[43mDocument\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Load a pre-trained embedding model from sentence_transformers\u001b[39;00m\n\u001b[1;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/langchain_core/documents/base.py:270\u001b[0m, in \u001b[0;36mDocument.__init__\u001b[0;34m(self, page_content, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Pass page_content in as positional or named arg.\"\"\"\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# my-py is complaining that page_content is not defined on the base class.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Here, we're relying on pydantic base class to handle the validation.\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpage_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/langchain_core/load/serializable.py:113\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Document\npage_content\n  str type expected (type=type_error.str)"
     ]
    }
   ],
   "source": [
    "# embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "# #text_splitter = SemanticChunker(embedding_function)\n",
    "\n",
    "\n",
    "\n",
    "# # Initialize the text splitter\n",
    "# text_splitter = CharacterTextSplitter(\n",
    "#     #separator=\"\\n\",  # Split based on newline characters\n",
    "#     chunk_size=100,  # Max number of characters in each chunk\n",
    "#     chunk_overlap=0  # No overlap between chunks\n",
    "# )\n",
    "\n",
    "# # Split the text into smaller chunks\n",
    "# text_chunks = text_splitter.create_documents(''.join(documentList))\n",
    "\n",
    "# # Create documents from the text chunks\n",
    "# docs = [Document(page_content=chunk) for chunk in text_chunks]\n",
    "\n",
    "# # Load a pre-trained embedding model from sentence_transformers\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# # Embed each document's content\n",
    "# embeddings = [model.encode(doc.page_content) for doc in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51ba717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.embeddings import AzureOpenAIEmbeddings, OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "all_texts = []\n",
    "\n",
    "embeddings_deployment = \"text-embedding-3-large\"\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=embeddings_deployment,\n",
    "    # With the `text-embedding-3` class\n",
    "    # of models, you can specify the size\n",
    "    # of the embeddings you want returned.\n",
    "    # dimensions=1024\n",
    ")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=50,\n",
    ")\n",
    "texts = text_splitter.split_text(''.join(documentList))\n",
    "\n",
    "# Add the chunks and metadata to the list\n",
    "all_texts.extend(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5865cbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_texts(\n",
    "    all_texts, embeddings#, metadatas=metadatas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ac3b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the text splitter\n",
    "# text_splitter = CharacterTextSplitter(\n",
    "#     separator=\"\\n\",  # Split based on newline characters\n",
    "#     chunk_size=100,  # Max number of characters in each chunk\n",
    "#     chunk_overlap=0  # No overlap between chunks\n",
    "# )\n",
    "\n",
    "# # Create documents using the text splitter\n",
    "# documents = text_splitter.create_documents([''.join(documentList)])\n",
    "\n",
    "# # Load a pre-trained embedding model from sentence_transformers\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# # Embed each document's content\n",
    "# for doc in documents:\n",
    "#     embedding = model.encode(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c515669c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "67fc4515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # storing embeddings in a folder\n",
    "# vector_store = Chroma.from_documents(docs, embedding_function, persist_directory=\"./chroma_db\")\n",
    "# # use this to load vector database\n",
    "# vector_store = Chroma(persist_directory=\"./chroma_db\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e8433c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Go through the context and answer given question strictly based on context. \n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm = ChatOpenAI(temperature=0),\n",
    "        # retriever=vector_store.as_retriever(search_kwargs={'k': 3}),\n",
    "        retriever=vector_store.as_retriever(),\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": PromptTemplate.from_template(PROMPT_TEMPLATE)}\n",
    "    )\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=ChatOpenAI(),\n",
    "                                       chain_type=\"stuff\",\n",
    "                                       retriever=vector_store.as_retriever(search_kwargs={\"k\": 1}),\n",
    "                                       return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": PromptTemplate.from_template(PROMPT_TEMPLATE)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3333ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"Who discovered the Galapagos Islands and how?\",\n",
    "    \"What is Brooklyn–Battery Tunnel?\",\n",
    "    \"Are Penguins found in the Galapagos Islands?\",\n",
    "    \"How many languages are spoken in New York?\",\n",
    "    \"In which countries are snow leopards found?\",\n",
    "    \"What are the threats to penguin populations?\",\n",
    "    \"What is the economic significance of New York City?\",\n",
    "    \"How did New York City get its name?\",\n",
    "    \"How did Galapagos Islands get its name?\",\n",
    "    \"What is the significance of the Statue of Liberty in New York City?\",\n",
    "    \n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    \"The Galapagos Islands were discovered in 1535 by the bishop of Panama, Tomás de Berlanga, whose ship had drifted off course while en route to Peru. He named them Las Encantadas (“The Enchanted”), and in his writings he marveled at the thousands of large galápagos (tortoises) found there. Numerous Spanish voyagers stopped at the islands from the 16th century, and the Galapagos also came to be used by pirates and by whale and seal hunters. \",\n",
    "    \"The Brooklyn-Battery Tunnel (officially known as the Hugh L. Carey Tunnel) is the longest continuous underwater vehicular tunnel in North America and runs underneath Battery Park, connecting the Financial District in Lower Manhattan to Red Hook in Brooklyn.[586]\",\n",
    "    \"Penguins live on the galapagos islands side by side with tropical animals.\",\n",
    "    \"As many as 800 languages are spoken in New York.\",\n",
    "    \"Siberia, Tajikistan, Kyrgyzstan, Uzbekistan, Kazakhstan, Afghanistan, Pakistan, India, Nepal, Bhutan, Mongolia, and Tibet.\",\n",
    "    \"The threats are numerous, including habitat loss, pollution, disease, and reduced food availability due to commercial fishing. Climate change is of particular concern for many species of penguin, as the sea ice that they depend on to find food or build nests is melting before their eyes.\",\n",
    "    \"New York City's economic significance is vast, as it serves as the global financial capital, housing Wall Street and major financial institutions. Its diverse economy spans technology, media, healthcare, education, and more, making it resilient to economic fluctuations. NYC is a hub for international business, attracting global companies, and boasts a large, skilled labor force. Its real estate market, tourism, cultural industries, and educational institutions further fuel its economic prowess. The city's transportation network and global influence amplify its impact on the world stage, solidifying its status as a vital economic player and cultural epicenter.\",\n",
    "    \"New York City got its name when it came under British control in 1664. King Charles II of England granted the lands to his brother, the Duke of York, who named the city New York in his own honor.\",\n",
    "    \"Tomás de Berlanga, who discovered the islands, named them Las Encantadas (“The Enchanted”), and in his writings he marveled at the thousands of large galápagos (tortoises) found there. Numerous Spanish voyagers stopped at the islands from the 16th century, and the Galapagos also came to be used by pirates and by whale and seal hunters.\",\n",
    "    \"The Statue of Liberty in New York City holds great significance as a symbol of the United States and its ideals of liberty and peace. It greeted millions of immigrants who arrived in the U.S. by ship in the late 19th and early 20th centuries, representing hope and freedom for those seeking a better life. It has since become an iconic landmark and a global symbol of cultural diversity and freedom.\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "52c2769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "contexts = []\n",
    "for query in queries:\n",
    "    result = qa_chain.invoke({\"query\": query})\n",
    "   \n",
    "    results.append(result['result'])\n",
    "    sources = result[\"source_documents\"]\n",
    "    contents = []\n",
    "    for i in range(len(sources)):\n",
    "        contents.append(sources[i].page_content)\n",
    "    contexts.append(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ff9ae7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['query', 'result', 'source_documents'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "23a10b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7863d4ba554d4d37997d2fca18fe1ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to parse output. Returning None.\n"
     ]
    }
   ],
   "source": [
    "d = {\n",
    "    \"question\": queries,\n",
    "    \"answer\": results,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truth\": ground_truths\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(d)\n",
    "score = evaluate(dataset,metrics=[faithfulness, answer_relevancy, context_precision, context_recall, context_entity_recall, answer_similarity, answer_correctness, harmfulness])\n",
    "score_df = score.to_pandas()\n",
    "score_df.to_csv(\"EvaluationScores.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "728bcb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faithfulness             1.000000\n",
       "answer_relevancy         0.760905\n",
       "context_precision        0.800000\n",
       "context_recall           0.683333\n",
       "context_entity_recall    0.326667\n",
       "answer_similarity        0.919008\n",
       "answer_correctness       0.756288\n",
       "harmfulness              0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df[['faithfulness','answer_relevancy', 'context_precision', 'context_recall',\n",
    "       'context_entity_recall', 'answer_similarity', 'answer_correctness',\n",
    "       'harmfulness']].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fdba5267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>context_entity_recall</th>\n",
       "      <th>answer_similarity</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>harmfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who discovered the Galapagos Islands and how?</td>\n",
       "      <td>The context does not mention anything about th...</td>\n",
       "      <td>[of the Hudson River, which he named Río de Sa...</td>\n",
       "      <td>The Galapagos Islands were discovered in 1535 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.820816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Brooklyn–Battery Tunnel?</td>\n",
       "      <td>The Brooklyn-Battery Tunnel is a vehicular tun...</td>\n",
       "      <td>[Park Service. Archived from the original on J...</td>\n",
       "      <td>The Brooklyn-Battery Tunnel (officially known ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.951870</td>\n",
       "      <td>0.737967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are Penguins found in the Galapagos Islands?</td>\n",
       "      <td>Yes, penguins can be spotted on the volcanic i...</td>\n",
       "      <td>[Learn more about each species of penguin and ...</td>\n",
       "      <td>Penguins live on the galapagos islands side by...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.972815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.910159</td>\n",
       "      <td>0.977540</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How many languages are spoken in New York?</td>\n",
       "      <td>As many as 800 languages are spoken in New Yor...</td>\n",
       "      <td>[2017. \"The immigrant share of the population ...</td>\n",
       "      <td>As many as 800 languages are spoken in New York.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995414</td>\n",
       "      <td>0.998854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which countries are snow leopards found?</td>\n",
       "      <td>Snow leopards are found in southern Siberia, T...</td>\n",
       "      <td>[Baikal through southern Siberia, in the Kunlu...</td>\n",
       "      <td>Siberia, Tajikistan, Kyrgyzstan, Uzbekistan, K...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.968004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.871289</td>\n",
       "      <td>0.967822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are the threats to penguin populations?</td>\n",
       "      <td>The threats to penguin populations include hab...</td>\n",
       "      <td>[ice or huddle together for warmth will melt t...</td>\n",
       "      <td>The threats are numerous, including habitat lo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.958360</td>\n",
       "      <td>0.864598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the economic significance of New York ...</td>\n",
       "      <td>The economic significance of New York City inc...</td>\n",
       "      <td>[metropolitan economy, with a gross metropolit...</td>\n",
       "      <td>New York City's economic significance is vast,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.905527</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.954169</td>\n",
       "      <td>0.827828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How did New York City get its name?</td>\n",
       "      <td>New York City was temporarily renamed New York...</td>\n",
       "      <td>[city in 1653. The city came under English con...</td>\n",
       "      <td>New York City got its name when it came under ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.953170</td>\n",
       "      <td>0.613292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How did Galapagos Islands get its name?</td>\n",
       "      <td>The context provided does not mention how the ...</td>\n",
       "      <td>[lynx), is where the Latin name uncia and the ...</td>\n",
       "      <td>Tomás de Berlanga, who discovered the islands,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.838250</td>\n",
       "      <td>0.209549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the significance of the Statue of Libe...</td>\n",
       "      <td>The Statue of Liberty was a reassuring sign fo...</td>\n",
       "      <td>[States ever since.\"  ^ The Immigrant's Statue...</td>\n",
       "      <td>The Statue of Liberty in New York City holds g...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.913256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.936578</td>\n",
       "      <td>0.609145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0      Who discovered the Galapagos Islands and how?   \n",
       "1                   What is Brooklyn–Battery Tunnel?   \n",
       "2       Are Penguins found in the Galapagos Islands?   \n",
       "3         How many languages are spoken in New York?   \n",
       "4        In which countries are snow leopards found?   \n",
       "5       What are the threats to penguin populations?   \n",
       "6  What is the economic significance of New York ...   \n",
       "7                How did New York City get its name?   \n",
       "8            How did Galapagos Islands get its name?   \n",
       "9  What is the significance of the Statue of Libe...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The context does not mention anything about th...   \n",
       "1  The Brooklyn-Battery Tunnel is a vehicular tun...   \n",
       "2  Yes, penguins can be spotted on the volcanic i...   \n",
       "3  As many as 800 languages are spoken in New Yor...   \n",
       "4  Snow leopards are found in southern Siberia, T...   \n",
       "5  The threats to penguin populations include hab...   \n",
       "6  The economic significance of New York City inc...   \n",
       "7  New York City was temporarily renamed New York...   \n",
       "8  The context provided does not mention how the ...   \n",
       "9  The Statue of Liberty was a reassuring sign fo...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [of the Hudson River, which he named Río de Sa...   \n",
       "1  [Park Service. Archived from the original on J...   \n",
       "2  [Learn more about each species of penguin and ...   \n",
       "3  [2017. \"The immigrant share of the population ...   \n",
       "4  [Baikal through southern Siberia, in the Kunlu...   \n",
       "5  [ice or huddle together for warmth will melt t...   \n",
       "6  [metropolitan economy, with a gross metropolit...   \n",
       "7  [city in 1653. The city came under English con...   \n",
       "8  [lynx), is where the Latin name uncia and the ...   \n",
       "9  [States ever since.\"  ^ The Immigrant's Statue...   \n",
       "\n",
       "                                        ground_truth  faithfulness  \\\n",
       "0  The Galapagos Islands were discovered in 1535 ...           1.0   \n",
       "1  The Brooklyn-Battery Tunnel (officially known ...           1.0   \n",
       "2  Penguins live on the galapagos islands side by...           1.0   \n",
       "3   As many as 800 languages are spoken in New York.           1.0   \n",
       "4  Siberia, Tajikistan, Kyrgyzstan, Uzbekistan, K...           1.0   \n",
       "5  The threats are numerous, including habitat lo...           1.0   \n",
       "6  New York City's economic significance is vast,...           1.0   \n",
       "7  New York City got its name when it came under ...           1.0   \n",
       "8  Tomás de Berlanga, who discovered the islands,...           1.0   \n",
       "9  The Statue of Liberty in New York City holds g...           1.0   \n",
       "\n",
       "   answer_relevancy  context_precision  context_recall  context_entity_recall  \\\n",
       "0          0.000000                0.0        0.000000               0.000000   \n",
       "1          0.991293                1.0        0.500000               0.500000   \n",
       "2          0.972815                1.0        1.000000               0.000000   \n",
       "3          0.992015                1.0        1.000000               1.000000   \n",
       "4          0.968004                1.0        1.000000               0.666667   \n",
       "5          0.999998                1.0        1.000000               0.250000   \n",
       "6          0.905527                1.0        1.000000               0.100000   \n",
       "7          0.866140                1.0        1.000000               0.500000   \n",
       "8          0.000000                0.0        0.000000               0.000000   \n",
       "9          0.913256                1.0        0.333333               0.250000   \n",
       "\n",
       "   answer_similarity  answer_correctness  harmfulness  \n",
       "0           0.820816                 NaN            0  \n",
       "1           0.951870            0.737967            0  \n",
       "2           0.910159            0.977540            0  \n",
       "3           0.995414            0.998854            0  \n",
       "4           0.871289            0.967822            0  \n",
       "5           0.958360            0.864598            0  \n",
       "6           0.954169            0.827828            0  \n",
       "7           0.953170            0.613292            0  \n",
       "8           0.838250            0.209549            0  \n",
       "9           0.936578            0.609145            0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc9fc37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
